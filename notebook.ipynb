{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import linear_model, metrics\n",
    "from scipy import interp\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_file = \"data/train.txt\"\n",
    "vocab_file = \"data/vocab.txt\"\n",
    "stopwords_file = \"data/stopwords.txt\"\n",
    "win_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "word_inds = {}\n",
    "with open(vocab_file, \"r\") as f:\n",
    "    s = f.read()\n",
    "    vocab = s.split(',')\n",
    "    \n",
    "for i, w in enumerate(vocab):\n",
    "    word_inds[w] = i\n",
    "stopwords = []\n",
    "with open(stopwords_file, \"r\") as f:\n",
    "    s = f.read()\n",
    "    stopwords = s.split(',')\n",
    "brands = [\"mercedes\", \"bmw\", \"mitsubishi\",\"тойота\",\"hyundai\",\"ford\",\"nissan\",\"audi\",\"lexus\",\n",
    "          \"chevrolet\",\"opel\",\"peugeot\",\"mazda\",\"лексус\",\"volvo\", \"мазд\", \"мицубись\", \"ситройня\", \n",
    "          \"киа\", \"renault\",\"kia\", \"toyota\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def f(word):\n",
    "    x = morph.parse(word)[0].normal_form\n",
    "    if re.match(\"[0-9]+\", x):\n",
    "        return \"_number\"\n",
    "    elif x in brands:\n",
    "        return \"_brand\"\n",
    "    else: return x\n",
    "\n",
    "def process_table(table):\n",
    "    data = table[1].str.split(',', 2).apply(pd.Series, 1)\n",
    "    data = data[data[2] != \"\"]\n",
    "    data[2] = data[2].apply(lambda x: str(x)[9:-3])\n",
    "    data.columns = [\"id\", \"label\", \"text\"]\n",
    "    data['label'] = data['label'].apply(lambda x: '1' if x == '3' or x == '4' else '0')\n",
    "    return data\n",
    "\n",
    "def process_text(text):\n",
    "    sample = re.split('\\W+', re.sub('\\W(Н|н)(е|Е) ', ' не', text))\n",
    "    l = [f(x) for x in sample if f(x) not in stopwords]\n",
    "    text = ' '.join(l)\n",
    "    return text\n",
    "\n",
    "def process(path):\n",
    "    data = pd.read_csv(path, delimiter='autoru-', header = None, quoting=3, engine='python')\n",
    "    data = process_table(data)\n",
    "    data['text'] = data['text'].apply(lambda x: process_text(x))\n",
    "    data.to_csv(path + \".proc.txt\", sep='\\t', encoding='utf-8')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_chunk(f, delimiter):\n",
    "    buf = \"\"\n",
    "    while True:\n",
    "        while delimiter in buf:\n",
    "            pos = buf.index(delimiter)\n",
    "            yield buf[:pos]\n",
    "            buf = buf[pos + len(delimiter):]\n",
    "        chunk = f.read(2048)\n",
    "        if not chunk:\n",
    "            yield buf\n",
    "            break\n",
    "        buf += chunk\n",
    "\n",
    "\n",
    "def get_data(input, flag):\n",
    "    data, labels = [], []\n",
    "    max_size = 0\n",
    "    if flag:\n",
    "        train_data = process(input)\n",
    "        data, labels = train_data['text'], train_data['label']\n",
    "        \n",
    "    else:\n",
    "        with open(input) as f:\n",
    "            gen = read_chunk(f, \"\\n\")\n",
    "            for i in range(40000):\n",
    "                s = next(gen).split('\\t')\n",
    "                data.append(s[-1])\n",
    "                max_size = max(max_size, len(s[-1].split()))\n",
    "                labels.append(s[-2])\n",
    "    return np.array(data), np.array(labels).astype(int), max_size\n",
    "\n",
    "data, labels, max_size = get_data(data_file, False)\n",
    "inv_labels = np.logical_not(labels)\n",
    "max_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_frequencies(some_data, out_file):\n",
    "    word_freq = {}\n",
    "    vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "    data_features = vectorizer.fit_transform(some_data).toarray()\n",
    "    words = vectorizer.get_feature_names()\n",
    "    frequencies = np.sum(data_features, axis=0)\n",
    "    #with open(out_file, \"w+\") as f:\n",
    "    for i, (fr, word) in enumerate(sorted(zip(frequencies, words), reverse=True)):\n",
    "        if word not in stopwords:\n",
    "            #f.write(str(fr) + ' ' + word + '\\n')\n",
    "            word_freq[word] = i + 1\n",
    "    return word_freq\n",
    "\n",
    "#good = get_word_frequencies(data[labels], \"data/clean_good_vocab.txt\")\n",
    "#bad = get_word_frequencies(data[inv_labels], \"data/clean_bad_vocab.txt\")\n",
    "\n",
    "def preprocess(data):\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            if data[i][j] != 0:\n",
    "                val = (bad[vocab[j]] if vocab[j] in bad else len(bad) / (good[vocab[j]] if vocab[j] in good else len(good)))\n",
    "                data[i][j] = data[i][j] * val\n",
    "            if not np.isfinite(data[i][j]):\n",
    "                print(vocab[j])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def contextwin(l, w_size, max_size):\n",
    "    assert (w_size % 2) == 1\n",
    "    assert w_size >= 1\n",
    "    l = list(l)\n",
    "    lpadded = (w_size // 2 * [-1]) + l + (max_size - len(l)) * [-1] + (w_size // 2 * [-1])\n",
    "    out = [lpadded[i:(i + w_size)] for i in range(max_size)]\n",
    "    return np.array(out).astype(int)\n",
    "\n",
    "def text_to_win(data, w_size, max_size):\n",
    "    inds = []\n",
    "    max_len = 0\n",
    "    for d in data:\n",
    "        \n",
    "        processed = np.array([word_inds[w] + 1 if w in vocab else 0 for w in d.split()])\n",
    "        max_len = len(processed) if len(processed) > max_len else max_len\n",
    "        x = contextwin(processed, w_size, max_size)\n",
    "        inds.append(np.array([contextwin(processed, w_size, max_size)]))\n",
    "    return inds, max_len\n",
    "processed_data, max_len = text_to_win(data, win_size, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1, 1084, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, max_size, win_size),input_var=input_var)\n",
    "    l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "        l_in, num_filters=32, filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "    l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool1, num_filters=32, filter_size=(2, 2),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))\n",
    "\n",
    "    l_dense1 = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(l_pool2, p=.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(l_dense1, p=.5),\n",
    "            num_units=2,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def with_NN(X_train, y_train, X_test, y_test):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    # Create neural network model\n",
    "    network = build_mlp(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.01, momentum=0.9)\n",
    "    \n",
    "    #validation\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "    # theano functions\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    test_fn = theano.function([input_var, target_var], test_prediction, on_unused_input='warn')\n",
    "    num_epochs = 20\n",
    "    # training\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        print (epoch)\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"  training loss:{:.6f},    validation loss:{:.6f}\".format(\n",
    "                train_err / train_batches, val_err / val_batches))\n",
    "        print(\"{},  validation accuracy:\\t\\t{:.2f} %\".format(epoch + 1, val_acc / val_batches * 100))\n",
    "    \n",
    "    test_err, test_acc, test_batches = 0, 0, 0\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    dtrain_predictions, dtrain_predprob, dtrain_targets = [], [], []\n",
    "    \n",
    "    for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        pred = test_fn(inputs, targets)\n",
    "        preds = [1 if fst < 0.5 else 0 for (fst, snd) in pred]\n",
    "        dtrain_predictions.extend(preds)\n",
    "        dtrain_predprob.extend([snd for (fst, snd) in pred])\n",
    "        dtrain_targets.extend(targets)\n",
    "        for value, prediction in zip(targets, preds):\n",
    "            if (prediction and value):\n",
    "                tp += 1\n",
    "            if (prediction and not value):\n",
    "                fp += 1\n",
    "            if (not prediction and value):\n",
    "                fn += 1\n",
    "            if (not prediction and not value):\n",
    "                tn += 1\n",
    "          \n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"NN:\")\n",
    "    print ('TP: {0}, TN: {1}, FP: {2}, FN: {3}'.format(tp, tn, fp, fn))\n",
    "    print (\"Precision Score : %f\" % metrics.precision_score(targets, preds))\n",
    "    print (\"Recall Score : %f\" % metrics.recall_score(targets, preds))\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(targets, preds)) \n",
    "    print (\"AUC : %f\" % metrics.roc_auc_score(targets, preds))\n",
    "    #print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    #print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))\n",
    "    return dtrain_predictions, dtrain_predprob, dtrain_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/Development/TOOLS/anaconda3/lib/python3.5/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n",
      "/Users/anastasia/Development/TOOLS/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:26: UserWarning: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: targets.\n",
      "To make this warning into an error, you can pass the parameter on_unused_input='raise' to theano.function. To disable it completely, use on_unused_input='ignore'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  training loss:41728712855801718370435664434356486348221534182598446069310921478641951453473788333126761911043549544184987382184809594880.000000,    validation loss:75302280491803929369303166188423131990338776799756120308355482087963373028767401448816735339965175243886016019300352000.000000\n",
      "1,  validation accuracy:\t\t93.61 %\n",
      "1\n",
      "  training loss:nan,    validation loss:nan\n",
      "2,  validation accuracy:\t\t93.61 %\n",
      "2\n",
      "  training loss:nan,    validation loss:nan\n",
      "3,  validation accuracy:\t\t93.61 %\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-64589d7327a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtestNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-64589d7327a6>\u001b[0m in \u001b[0;36mtestNN\u001b[0;34m(with_probas)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#X_test = preprocess(X_test.toarray())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwith_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-f48d3111d48a>\u001b[0m in \u001b[0;36mwith_NN\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anastasia/Development/TOOLS/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def testNN(with_probas=True):\n",
    "    cv = StratifiedKFold(labels, n_folds=5)\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "        #features = vectorizer.fit_transform(data[train])\n",
    "        \n",
    "        # preprocessing with tfidf\n",
    "        #transformer = TfidfTransformer()\n",
    "        #tfidf_features = transformer.fit(features).transform(features)\n",
    "        #X = tfidf_features.toarray()\n",
    "        \n",
    "        # preprocessing with bad/good ranking\n",
    "        #X_train = preprocess(features.toarray())\n",
    "        \n",
    "        X_train, y_train = np.array(processed_data)[train], np.array(labels[train]).astype(np.int32)\n",
    "        X_test, y_test = np.array(processed_data)[test], np.array(labels[test]).astype(np.int32)\n",
    "        #X_test = preprocess(X_test.toarray())\n",
    "        \n",
    "        res, res_p, l = with_NN(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(l, res_p)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        check = zip(y_test, res)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for value, prediction in check:\n",
    "            if (prediction and value):\n",
    "                tp += 1\n",
    "            if (prediction and not value):\n",
    "                fp += 1 \n",
    "            if (not prediction and value):\n",
    "                fn += 1\n",
    "            if (not prediction and not value):\n",
    "                tn += 1\n",
    "        print ('TP: {0}, TN: {1}, FP: {2}, FN: {3}'.format(tp, tn, fp, fn))\n",
    "        print (\"Precision Score : %f\" % metrics.precision_score(y_test, res))\n",
    "        print (\"Recall Score : %f\" % metrics.recall_score(y_test, res))\n",
    "        print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, res))\n",
    "    if with_probas:\n",
    "        plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "testNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def with_all(d_train, l_train, d_test, l_test):\n",
    "    #clf1 = RandomForestClassifier(n_estimators=20)\n",
    "    skf = list(StratifiedKFold(l_train, 5))\n",
    "\n",
    "    clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "            GradientBoostingClassifier(subsample=0.5, max_depth=6, n_estimators=50)]\n",
    "    \n",
    "    dataset_blend_train = np.zeros((d_train.shape[0], len(clfs)))\n",
    "    dataset_blend_test = np.zeros((d_test.shape[0], len(clfs)))\n",
    "    \n",
    "    for j, clf in enumerate(clfs):\n",
    "        print (clf)\n",
    "        dataset_blend_test_j = np.zeros((d_test.shape[0], len(skf)))\n",
    "        for i, (train, test) in enumerate(skf):\n",
    "            X_train = d_train[train]\n",
    "            y_train = l_train[train]\n",
    "            X_test = d_train[test]\n",
    "            y_test = l_train[test]\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_submission = clf.predict_proba(X_test)[:,1]\n",
    "            dataset_blend_train[test, j] = y_submission\n",
    "            dataset_blend_test_j[:, i] = clf.predict_proba(d_test)[:,1]\n",
    "        dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(dataset_blend_train, l_train)\n",
    "    dtrain_predprob = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "    dtrain_predictions = [1 if dtrain_predprob[i] > 0.42 else 0 for i in range(len(dtrain_predprob))]\n",
    "    check = zip(l_test, dtrain_predictions)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for value, prediction in check:\n",
    "        if (prediction and value):\n",
    "            tp += 1\n",
    "        if (prediction and not value):\n",
    "            fp += 1 \n",
    "        if (not prediction and value):\n",
    "            fn += 1\n",
    "        if (not prediction and not value):\n",
    "            tn += 1\n",
    "    print ('All: TP: {0}, TN: {1}, FP: {2}, FN: {3}'.format(tp, tn, fp, fn))\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(l_test, dtrain_predictions))\n",
    "    print (\"AUC : %f\" % metrics.roc_auc_score(l_test, dtrain_predprob))\n",
    "    print (\"Precision : %f\" % metrics.precision_score(l_test, dtrain_predictions))\n",
    "    print (\"Recall : %f\" % metrics.recall_score(l_test, dtrain_predictions))\n",
    "    return dtrain_predictions, dtrain_predprob\n",
    "\n",
    "def with_KNN(X_train, y_train, X_test, y_test):\n",
    "    X, X1, y, y1 = train_test_split(X_train, y_train, test_size=0.5)\n",
    "    clf1 = RandomForestClassifier(n_estimators=40)\n",
    "    clf2 = KNeighborsClassifier()\n",
    "    enc = OneHotEncoder()\n",
    "    clf1.fit(X, y)\n",
    "    enc.fit(clf1.apply(X))\n",
    "    clf2.fit(enc.transform(clf1.apply(X1)), y1)\n",
    "    res = clf2.predict(enc.transform(clf1.apply(X_test))) \n",
    "    res_p = clf2.predict_proba(enc.transform(clf1.apply(X_test)))[:, 1]\n",
    "    #feat_imp = sorted(zip(clf2.feature_importances_, range(len(vocab))), reverse=True)\n",
    "    check = zip(y_test, res)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for value, prediction in check:\n",
    "        if (prediction and value):\n",
    "            tp += 1\n",
    "        if (prediction and not value):\n",
    "            fp += 1 \n",
    "        if (not prediction and value):\n",
    "            fn += 1\n",
    "        if (not prediction and not value):\n",
    "            tn += 1\n",
    "    print (' KNN: TP: {0}, TN: {1}, FP: {2}, FN: {3}'.format(tp, tn, fp, fn))\n",
    "    print (\"Precision Score : %f\" % metrics.precision_score(y_test, res))\n",
    "    print (\"Recall Score : %f\" % metrics.recall_score(y_test, res))\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, res))\n",
    "    return res, res_p\n",
    "        \n",
    "def with_XGB(X_train, y_train, X_test, y_test):\n",
    "    clf = XGBClassifier(learning_rate =0.03, n_estimators=150, max_depth=6,\n",
    "                        min_child_weight=4, gamma=0.1, subsample=0.8, \n",
    "                        colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "                        nthread=4, scale_pos_weight=1, seed=27)\n",
    "    clf.fit(X_train, y_train)\n",
    "    res = clf.predict(X_test)\n",
    "    res_p = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    feat_imp = pd.Series(clf.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_ind = [ vocab[int(f[1:])] for f in feat_imp.index]\n",
    "    words_imp = zip(feat_imp.values, feat_ind)\n",
    "    #print((list)words_imp[:10])\n",
    "    check = zip(y_test, res)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for value, prediction in check:\n",
    "        if (prediction and value):\n",
    "            tp += 1\n",
    "        if (prediction and not value):\n",
    "            fp += 1 \n",
    "        if (not prediction and value):\n",
    "            fn += 1\n",
    "        if (not prediction and not value):\n",
    "            tn += 1\n",
    "    print ('XGB: TP: {0}, TN: {1}, FP: {2}, FN: {3}'.format(tp, tn, fp, fn))\n",
    "    print (\"Precision Score : %f\" % metrics.precision_score(y_test, res))\n",
    "    print (\"Recall Score : %f\" % metrics.recall_score(y_test, res))\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, res))\n",
    "    #feat_imp = sorted(zip(clf2.feature_importances_, range(len(vocab))), reverse=True)\n",
    "    return res, res_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              presort='auto', random_state=None, subsample=0.5, verbose=0,\n",
      "              warm_start=False)\n",
      "All: TP: 122, TN: 7429, FP: 50, FN: 399\n",
      "Accuracy : 0.9439\n",
      "AUC : 0.820410\n",
      "Precision : 0.709302\n",
      "Recall : 0.234165\n",
      "XGB: TP: 60, TN: 7455, FP: 24, FN: 461\n",
      "Precision Score : 0.714286\n",
      "Recall Score : 0.115163\n",
      "Accuracy : 0.9394\n",
      " KNN: TP: 119, TN: 7402, FP: 77, FN: 402\n",
      "Precision Score : 0.607143\n",
      "Recall Score : 0.228407\n",
      "Accuracy : 0.9401\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEZCAYAAACervI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Kf8HwK2mk86x+vdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28659c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test(with_probas=True):\n",
    "    cv = StratifiedKFold(labels, n_folds=5)\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        if i == 0:\n",
    "            vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "            features = vectorizer.fit_transform(data[train])\n",
    "\n",
    "            # preprocessing with tfidf\n",
    "            #transformer = TfidfTransformer()\n",
    "            #tfidf_features = transformer.fit(features).transform(features)\n",
    "            #X = tfidf_features.toarray()\n",
    "\n",
    "            # preprocessing with bad/good ranking\n",
    "            #X_train = preprocess(features.toarray())\n",
    "\n",
    "            X_train, y_train = features.toarray(), labels[train]\n",
    "            X_test, y_test = vectorizer.transform(data[test]).toarray(), labels[test]\n",
    "            #X_test = preprocess(X_test.toarray())\n",
    "\n",
    "            res, res_p = with_all(X_train, y_train, X_test, y_test)\n",
    "            fpr, tpr, _ = roc_curve(y_test, res_p)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=1, label='Ensemble (area = %0.2f)' % (roc_auc))            \n",
    "            \n",
    "            res, res_p = with_XGB(X_train, y_train, X_test, y_test)\n",
    "            fpr, tpr, _ = roc_curve(y_test, res_p)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=1, label='XGB (area = %0.2f)' % (roc_auc))            \n",
    "            \n",
    "            res, res_p = with_KNN(X_train, y_train, X_test, y_test)\n",
    "            fpr, tpr, _ = roc_curve(y_test, res_p)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=1, label='KNN+RF (area = %0.2f)' % (roc_auc))\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "            plt.xlim([-0.05, 1.05])\n",
    "            plt.ylim([-0.05, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic example')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
